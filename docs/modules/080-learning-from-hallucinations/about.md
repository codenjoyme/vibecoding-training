# Learning from Hallucinations

**Duration:** 5-7 minutes  
**Skill:** Transform AI output deviations into instruction improvements by delegating fixes to the agent itself

**ðŸ‘‰ [Start hands-on walkthrough](walkthrough.md)**

## Topics

- Recognizing when AI output deviates from expectations (hallucinations)
- Understanding hallucinations as ambiguity feedback, not errors
- Stopping the agent when deviations occur
- Delegating instruction fixes to AI instead of manual editing
- Iterative refinement: fix â†’ retest â†’ verify
- Maintaining instruction consistency using creating-instructions pattern
- Building self-improving instruction systems

## Learning Outcome

Stop editing instructions manuallyâ€”delegate refinements to your AI agent, creating a self-improving instruction system that learns from every deviation.

## Prerequisites

- Complete [Custom Instructions](../070-custom-instructions/about.md) module
- Understanding of instruction file structure
- Experience with AI agent workflows

## When to Use

- Every time AI output surprises you or doesn't match expectations
- When building reusable instruction libraries for team use
- During iterative development to capture and fix ambiguities
- To maintain consistency across multiple instruction files
- When the same type of mistake repeatsâ€”fix it once in the instruction
